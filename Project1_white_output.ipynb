# Import everything needed to edit/save/watch video clips
from moviepy.editor import VideoFileClip
from IPython.display import HTML
#importing some useful packages
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import cv2
%matplotlib inline


def pipeline(image):
    # Params for region of interest
    bot_left = [80, 540]
    bot_right = [980, 540]
    apex_right = [510, 315]
    apex_left = [450, 315]
    v = [np.array([bot_left, bot_right, apex_right, apex_left], dtype=np.int32)]   
    #gray an image 
    gray = grayscale(image)
     # Define a kernel size for Gaussian smoothing / blurring
    kernel_size = 5 
    blur_gray = gaussian_blur(gray,kernel_size)
    # Define our parameters for Canny and run it
    low_threshold = 50
    high_threshold = 125
    edges = canny(blur_gray, low_threshold, high_threshold)
    #mask the region of interest
    masked_edges = region_of_interest(edges, v)
    # Define the Hough transform parameters
    # Make a blank the same size as our image to draw on
    rho = 0.8 # distance resolution in pixels of the Hough grid
    theta = np.pi/180 # angular resolution in radians of the Hough grid
    threshold = 25     # minimum number of votes (intersections in Hough grid cell)
    min_line_length = 50 #minimum number of pixels making up a line
    max_line_gap = 200    # maximum gap in pixels between connectable line segments
    #line_image = np.copy(image)*0 # creating a blank to draw lines on
    # Run Hough on edge detected image
    # Output "lines" is an array containing endpoints of detected line segments
    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),min_line_length, max_line_gap)
    
    # separate by postite and negative slope
    
    right_lines, left_lines = separate_lines(lines)
    right = line_outliers(right_lines,  cutoff=(0.45, 0.8))
    right = lines_mean(right)

    left = line_outliers(left_lines, cutoff=(-0.85, -0.7))
    left = lines_mean(left)

    lines = np.concatenate((right, left))
    
    #draw lines
    line_img = np.copy((image)*0)
    draw_lines(line_img, lines, thickness=10)
    
    # Return final image 
    line_img = region_of_interest(line_img, v)
    add_lines_to_initial  = weighted_img(line_img, image)


    return add_lines_to_initial 


def process_image(image):
    # NOTE: The output you return should be a color image (3 channel) for processing video below
    # TODO: put your pipeline here,
    # you should return the final output (image with lines are drawn on lanes)

    result = pipeline(image)
    return result

white_output = 'final.mp4'
## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video
## To do so add .subclip(start_second,end_second) to the end of the line below
## Where start_second and end_second are integer values representing the start and end of the subclip
## You may also uncomment the following line for a subclip of the first 5 seconds
##clip1 = VideoFileClip("solidWhiteRight.mp4").subclip(0,5)
clip1 = VideoFileClip("solidWhiteRight.mp4")
white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!
%time white_clip.write_videofile(white_output, audio=False)

HTML("""
<video width="960" height="540" controls>
  <source src="{0}">
</video>
""".format(white_output))
